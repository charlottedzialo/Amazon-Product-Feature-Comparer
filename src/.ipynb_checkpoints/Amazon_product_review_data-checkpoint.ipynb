{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import pyspark as ps    # for the pyspark suite\n",
    "import os               # for environ variables in Part 3\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "spark = ps.sql.SparkSession.builder \\\n",
    "            .appName('capstone') \\\n",
    "            .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reviews = spark.read.csv('Data/amazon_small.tsv', sep='\\t', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_beauty = df_reviews.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(url):\n",
    "    \n",
    "    ''' \n",
    "    1. create new columns with review headline + review text\n",
    "    2. create new df  \n",
    "    3. Remove products with no reviews\n",
    "    4. Calls clean text, to clean the text reviews\n",
    "    5. Drops old text review\n",
    "    6. Calculates the sentiment \n",
    "    7. Calls get_aspects to get key words\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    cols=['marketplace', 'customer_id', 'review_id', 'product_id',\n",
    "       'product_parent', 'product_title', 'product_category', 'star_rating',\n",
    "       'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
    "       'review_headline', 'review_body', 'review_date'] \n",
    "\n",
    "    df = pd.read_csv(url, sep = '\\t', names = cols)\n",
    "    df['review_text'] = df['review_headline']+\". \"+ df['review_body']\n",
    "    df = pd.concat([df['product_id'], \n",
    "                    df['product_title'], \n",
    "                    df['review_text'],\n",
    "                    df['star_rating']],axis=1)\n",
    "    \n",
    "    \n",
    "    df = df[pd.notnull(df['review_text'])]\n",
    "    \n",
    "    df['clean_text'] = df['review_text'].apply(text_cleaner)\n",
    "    \n",
    "    df = df.drop('review_text', axis=1)\n",
    "    \n",
    "    df['sentiment_score'] = df['clean_text'].apply(sentiment_analyzer_scores)\n",
    "    \n",
    "    df['key_words'] = df['clean_text'].apply(get_aspects)\n",
    "    \n",
    "    df['key_words'] = df['key_words'].apply(', '.join)\n",
    "\n",
    "    \n",
    "    return df \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import numpy as np \n",
    "\n",
    "\n",
    "def text_cleaner(name): \n",
    "    \n",
    "    \n",
    "    ''' \n",
    "    Text cleaner is called in the clean data function. \n",
    "    Takes in text and cleans it. \n",
    "    \n",
    "    '''\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', name)\n",
    "    cleantext = str(cleantext).lower()\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#|$|%]',r'',cleantext)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    cleaned = str(cleaned).lower()\n",
    "    \n",
    "    #removing accented characters\n",
    "    cleaned = unicodedata.normalize('NFKD', cleaned).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    \n",
    "    return cleaned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "def sentiment_analyzer_scores(sentence):\n",
    "    \n",
    "    \n",
    "    ''' \n",
    "    Returns Compound score for each sentence.\n",
    "    The Compound score is a metric that calculates \n",
    "    the sum of all the lexicon ratings \n",
    "    which have been normalized between \n",
    "    -1(most extreme negative) and +1 (most extreme positive)\n",
    "    \n",
    "    '''\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    return score['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NMF' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-d9f06c9d49a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Fit the NMF model with tf-idf features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m nmf = NMF(n_components=n_components, random_state=1,\n\u001b[0m\u001b[1;32m     29\u001b[0m           alpha=.1, l1_ratio=.5).fit(tfidf)\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NMF' is not defined"
     ]
    }
   ],
   "source": [
    "n_samples = 10000\n",
    "n_features = 10000\n",
    "n_components = 10\n",
    "n_top_words = 10\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"Topic #%d: \" % topic_idx\n",
    "        message += \" \".join([feature_names[i]\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])\n",
    "        print(message)\n",
    "\n",
    "\n",
    "# Use tf-idf features for NMF.\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.95, min_df=2,\n",
    "                                   max_features=n_features,\n",
    "                                   stop_words='english')\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(prod_B[\"clean_text\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fit the NMF model with tf-idf features\n",
    "\n",
    "nmf = NMF(n_components=n_components, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "\n",
    "\n",
    "# Topics in NMF model (Frobenius norm)\n",
    "\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()\n",
    "print_top_words(nmf, tfidf_feature_names, n_top_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LatentDirichletAllocation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-c7595ac8e680>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n\u001b[0m\u001b[1;32m     12\u001b[0m                                 \u001b[0mlearning_method\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'online'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                 \u001b[0mlearning_offset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LatentDirichletAllocation' is not defined"
     ]
    }
   ],
   "source": [
    "#Fitting LDA models with tf features\n",
    "\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "\n",
    "tf = tf_vectorizer.fit_transform(prod_B[\"clean_text\"])\n",
    "\n",
    "\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=n_components, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "\n",
    "\n",
    "lda.fit(tf)\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "## NEED TO FIGURE OUT THE CORRECT AMOUNT OF FEATURES: USING GRID SEARCH?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Practing with two products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_A = data_cleaning('Data/test_product_A.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_B = data_cleaning('Data/test_product_B.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "prodab = pd.concat([prod_A, prod_B])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one', 'travel', 'hair', 'bag', 'style', 'flatiron', 'cloth']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Create a list of common words to remove\"\"\"\n",
    "stop_words=[\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \n",
    "            \"yourselves\", \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \n",
    "            \"they\", \"them\", \"their\", \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \n",
    "            \"those\", \"am\", \"is\", \"are\", \"was\", \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \n",
    "            \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\", \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \n",
    "            \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\", \"into\", \"through\", \"during\", \"before\", \n",
    "            \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\", \"over\", \"under\", \"again\", \n",
    "            \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\", \"both\", \"each\", \n",
    "            \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\n",
    "            \"too\", \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\", \"nice\"]\n",
    "\n",
    "\n",
    "\"\"\"Load the pre-trained NLP model in spacy\"\"\"\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "\"\"\"Define a function to extract keywords\"\"\"\n",
    "\n",
    "def get_aspects(x):\n",
    "\n",
    "    \n",
    "    \"\"\"Apply the function to get aspects from reviews\"\"\"\n",
    "\n",
    "    doc=nlp(x) ## Tokenize and extract grammatical components\n",
    "    doc=[i.text for i in doc if i.text not in stop_words and i.pos_==\"NOUN\"] ## Remove common words and retain only nouns\n",
    "    doc=list(map(lambda i: i.lower(),doc)) ## Normalize text to lower case\n",
    "    doc=pd.Series(doc)\n",
    "    doc=doc.value_counts().head(11).index.tolist() ## Get 5 most frequent nouns\n",
    "    return doc\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Apply the function to get aspects from reviews\"\"\"\n",
    "get_aspects(prod_B['clean_text'][10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>key_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>3</td>\n",
       "      <td>great to keep them white  not so great to get ...</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>teeth, product, step, gel, crest, whitestrips,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>3</td>\n",
       "      <td>not so great for sensitive teeth  i was super ...</td>\n",
       "      <td>0.9359</td>\n",
       "      <td>step, day, teeth, system, use, mission, coffee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>fresh from the dentist clean  smooth  white te...</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>teeth, system, brilliance, cleansing, dentist,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>i liked how this product cleaned my teeth and ...</td>\n",
       "      <td>0.8689</td>\n",
       "      <td>product, teeth, whitening, tube, tubes, mouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>great at home whitening maintenance  ive been ...</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>home, whitening, brilliance, cleansing, thanks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>2</td>\n",
       "      <td>good product  just not for people with sensiti...</td>\n",
       "      <td>-0.6385</td>\n",
       "      <td>teeth, product, people, mouth, parts, crest, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>easy system  i love this system  i recieved th...</td>\n",
       "      <td>0.9659</td>\n",
       "      <td>system, teeth, diffrent, time, way, mouthwashe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>great whitening product  great whitening produ...</td>\n",
       "      <td>0.9359</td>\n",
       "      <td>product, whitening, kit, dentist, results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>smileverous  not only did i love this product ...</td>\n",
       "      <td>0.9851</td>\n",
       "      <td>product, friends, mission, word, smile, review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>3</td>\n",
       "      <td>its okay  i dont really see any benefits from ...</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>product, step, whitening, week, time, products...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>crest 3d white brilliance  this is a very good...</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>product, bed, right, mouth, process, feeling, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>good and effective  i received the crest 3d wh...</td>\n",
       "      <td>0.9702</td>\n",
       "      <td>system, crest, one, teeth, cleansing, coffee, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>try it  your like it  i did not buy this produ...</td>\n",
       "      <td>0.9303</td>\n",
       "      <td>product, teeth, amazon, everyone, people, expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>3</td>\n",
       "      <td>okay product  i was very excited to get this p...</td>\n",
       "      <td>0.8944</td>\n",
       "      <td>step, product, cap, days, teeth, toothpaste, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>my teeth have never felt healthier  i was luck...</td>\n",
       "      <td>0.9246</td>\n",
       "      <td>teeth, pregnancy, product, answer, time, tooth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>love it  i love how my teeth feel after using ...</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>teeth, product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>good product with some reservations  the produ...</td>\n",
       "      <td>0.8221</td>\n",
       "      <td>areas, results, sensitivity, teeth, product, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>shiny teeth  fresh breath  i really liked the ...</td>\n",
       "      <td>0.9596</td>\n",
       "      <td>breath, products, teeth, mouth, time, whiter, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>white  white  white and white love this toothp...</td>\n",
       "      <td>0.9552</td>\n",
       "      <td>sample, love, crest, smile, thanks, toothpaste</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>3</td>\n",
       "      <td>brighter  not whiter  smile  i liked the taste...</td>\n",
       "      <td>0.6980</td>\n",
       "      <td>toothpaste, spots, gums, feeling, label, produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>loving the results  i was given a chance to tr...</td>\n",
       "      <td>0.9841</td>\n",
       "      <td>product, whiter, paste, teeth, chance, mail, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>a good whitening option  i thought that my cre...</td>\n",
       "      <td>0.9727</td>\n",
       "      <td>teeth, toothpaste, day, steps, strips, work, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>sparkly smile  this stuff is great i am sure t...</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>difference, it-, stuff, part, minutes, mouth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>nice presentation  nice taste  but       my fi...</td>\n",
       "      <td>0.9863</td>\n",
       "      <td>product, taste, gums, tubes, minutes, day, pac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>skeptical at first  great experience  i receiv...</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>difference, brilliance, teeth, products, issue...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>tried it and liked it  i got a free trial of t...</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>difference, trial, anyone, money, way, product...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>a great expierence  i found that it really hel...</td>\n",
       "      <td>0.8979</td>\n",
       "      <td>teeth, expierence, stuff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>2</td>\n",
       "      <td>teeth became too sensitive  i got to try this ...</td>\n",
       "      <td>-0.2803</td>\n",
       "      <td>teeth, use, fan, weeks, bzzagent, product, crest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>works amazing  im a coffee drinker with sensit...</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>teeth, picture, paste, crest, coffee, drinker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>i love the way the system makes my teeth feel ...</td>\n",
       "      <td>0.9118</td>\n",
       "      <td>way, system, teeth, guinea, color, bzzagent, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>i really like how it has whiten my teeth with ...</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>non, crest, whitening, teeth, future, sensitiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>i really like this i have always used a daily ...</td>\n",
       "      <td>0.9915</td>\n",
       "      <td>whitening, teeth, steps, lot, difference, coff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>get brilliant white teeth with crest 3d white ...</td>\n",
       "      <td>0.9826</td>\n",
       "      <td>crest, teeth, brilliance, product, minute, ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>this works great   i was lucky enough to recei...</td>\n",
       "      <td>0.9697</td>\n",
       "      <td>teeth, trays, whiter, couple, cream, crest, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>it actually works   im surprised  got the oppo...</td>\n",
       "      <td>0.9927</td>\n",
       "      <td>one, day, teeth, today, pictures, difference, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>works wonders  a shout out to crest for sendin...</td>\n",
       "      <td>0.9511</td>\n",
       "      <td>whitening, teeth, time, difference, toothpaste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>worth it  ive been using crest 3d whiteTM bril...</td>\n",
       "      <td>0.9694</td>\n",
       "      <td>teeth, toothpaste, step, crest, product, side,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>2 step teeth care product that whitens your sm...</td>\n",
       "      <td>0.9741</td>\n",
       "      <td>product, teeth, step, smile, cleanser, flavor,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>dentist results at home  this new crest 3d whi...</td>\n",
       "      <td>0.9631</td>\n",
       "      <td>system, step, toothpaste, results, tube, denti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>want whiter teeth this is for you  if you have...</td>\n",
       "      <td>0.9321</td>\n",
       "      <td>teeth, whiter, week, difference, whitens, test...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>894</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>im in love with this toothpaste  im in love wi...</td>\n",
       "      <td>0.3837</td>\n",
       "      <td>love, toothpaste, week, set, kit, results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>truely is an amazing product  i received the c...</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>system, brilliance, kit, step, crest, use, mou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>product first week impressions  having white t...</td>\n",
       "      <td>0.9795</td>\n",
       "      <td>product, teeth, toothpaste, step, mouth, textu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>bzz review  so ill start by saying that i drin...</td>\n",
       "      <td>0.7910</td>\n",
       "      <td>teeth, step, product, day, mouth, plenty, peop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>prevents stains  i love love love this toothpa...</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>teeth, product, toothpaste, stains, wine, ques...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>2</td>\n",
       "      <td>ouch - step 1 can cause staining  step 2 can c...</td>\n",
       "      <td>0.9844</td>\n",
       "      <td>step, teeth, product, fluoride, gel, damage, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>finally doesnt make my teeth sensitive   i abs...</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>teeth, products, product, difference, cleansin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>shiny happy teeth  so far so good ive been usi...</td>\n",
       "      <td>0.9890</td>\n",
       "      <td>teeth, texture, sample, week, smile, gunk, cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>3</td>\n",
       "      <td>thanks for adding this to my whitening lineup ...</td>\n",
       "      <td>0.9274</td>\n",
       "      <td>thanks, lineup, whitening, health, appearance,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>bright product  i love the new crest 3d white ...</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>system, results, product, crest, toothpaste, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>my honest opinion about the product is it is g...</td>\n",
       "      <td>0.9744</td>\n",
       "      <td>product, toothpaste, opinion, agents, cap, foa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>this is a great product  i used it one time an...</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>product, time, minute, staining, teeth, taste,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>amazing duo  i drink tea and have not been abl...</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>teeth, duo, bzzzagent, dentist, time, shade, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>a nice maintenance whitening product for regul...</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>product, teeth, peroxide, whitening, crest, te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>will definitely buy again  i absolutely love t...</td>\n",
       "      <td>0.9359</td>\n",
       "      <td>week, part, bzzagent, product, crest, teeth, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>fast  easy  results   i had the please of tryi...</td>\n",
       "      <td>0.9743</td>\n",
       "      <td>results, whitening, teeth, product, strips, mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>4</td>\n",
       "      <td>good product  i received the crest 3d white br...</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>teeth, product, system, difference, minute, cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>3</td>\n",
       "      <td>fresh breath feel  i was very excited to recei...</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>breath, week, difference, tube, freebie, bzzag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>crest is the best  i am trying this product fo...</td>\n",
       "      <td>0.9393</td>\n",
       "      <td>teeth, product, difference, hundreds, counter,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>B00ZKLLZAI</td>\n",
       "      <td>Crest 3D White Brilliance Toothpaste, Teeth Wh...</td>\n",
       "      <td>5</td>\n",
       "      <td>this new product is completely different and h...</td>\n",
       "      <td>0.9459</td>\n",
       "      <td>product, taste, crest, minty, past, difference...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>914 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     product_id                                      product_title  \\\n",
       "0    B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "1    B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "2    B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "3    B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "4    B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "5    B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "6    B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "7    B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "8    B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "9    B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "10   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "11   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "12   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "13   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "14   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "15   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "16   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "17   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "18   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "19   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "20   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "21   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "22   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "23   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "24   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "25   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "26   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "27   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "28   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "29   B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "..          ...                                                ...   \n",
       "884  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "885  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "886  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "887  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "888  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "889  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "890  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "891  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "892  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "893  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "894  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "895  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "896  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "897  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "898  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "899  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "900  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "901  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "902  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "903  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "904  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "905  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "906  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "907  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "908  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "909  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "910  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "911  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "912  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "913  B00ZKLLZAI  Crest 3D White Brilliance Toothpaste, Teeth Wh...   \n",
       "\n",
       "     star_rating                                         clean_text  \\\n",
       "0              3  great to keep them white  not so great to get ...   \n",
       "1              3  not so great for sensitive teeth  i was super ...   \n",
       "2              5  fresh from the dentist clean  smooth  white te...   \n",
       "3              4  i liked how this product cleaned my teeth and ...   \n",
       "4              4  great at home whitening maintenance  ive been ...   \n",
       "5              2  good product  just not for people with sensiti...   \n",
       "6              5  easy system  i love this system  i recieved th...   \n",
       "7              5  great whitening product  great whitening produ...   \n",
       "8              5  smileverous  not only did i love this product ...   \n",
       "9              3  its okay  i dont really see any benefits from ...   \n",
       "10             4  crest 3d white brilliance  this is a very good...   \n",
       "11             4  good and effective  i received the crest 3d wh...   \n",
       "12             4  try it  your like it  i did not buy this produ...   \n",
       "13             3  okay product  i was very excited to get this p...   \n",
       "14             5  my teeth have never felt healthier  i was luck...   \n",
       "15             4  love it  i love how my teeth feel after using ...   \n",
       "16             5  good product with some reservations  the produ...   \n",
       "17             4  shiny teeth  fresh breath  i really liked the ...   \n",
       "18             5  white  white  white and white love this toothp...   \n",
       "19             3  brighter  not whiter  smile  i liked the taste...   \n",
       "20             5  loving the results  i was given a chance to tr...   \n",
       "21             4  a good whitening option  i thought that my cre...   \n",
       "22             5  sparkly smile  this stuff is great i am sure t...   \n",
       "23             4  nice presentation  nice taste  but       my fi...   \n",
       "24             5  skeptical at first  great experience  i receiv...   \n",
       "25             5  tried it and liked it  i got a free trial of t...   \n",
       "26             5  a great expierence  i found that it really hel...   \n",
       "27             2  teeth became too sensitive  i got to try this ...   \n",
       "28             5  works amazing  im a coffee drinker with sensit...   \n",
       "29             4  i love the way the system makes my teeth feel ...   \n",
       "..           ...                                                ...   \n",
       "884            4  i really like how it has whiten my teeth with ...   \n",
       "885            5  i really like this i have always used a daily ...   \n",
       "886            5  get brilliant white teeth with crest 3d white ...   \n",
       "887            5  this works great   i was lucky enough to recei...   \n",
       "888            5  it actually works   im surprised  got the oppo...   \n",
       "889            5  works wonders  a shout out to crest for sendin...   \n",
       "890            4  worth it  ive been using crest 3d whiteTM bril...   \n",
       "891            4  2 step teeth care product that whitens your sm...   \n",
       "892            5  dentist results at home  this new crest 3d whi...   \n",
       "893            5  want whiter teeth this is for you  if you have...   \n",
       "894            5  im in love with this toothpaste  im in love wi...   \n",
       "895            5  truely is an amazing product  i received the c...   \n",
       "896            4  product first week impressions  having white t...   \n",
       "897            5  bzz review  so ill start by saying that i drin...   \n",
       "898            5  prevents stains  i love love love this toothpa...   \n",
       "899            2  ouch - step 1 can cause staining  step 2 can c...   \n",
       "900            5  finally doesnt make my teeth sensitive   i abs...   \n",
       "901            4  shiny happy teeth  so far so good ive been usi...   \n",
       "902            3  thanks for adding this to my whitening lineup ...   \n",
       "903            5  bright product  i love the new crest 3d white ...   \n",
       "904            4  my honest opinion about the product is it is g...   \n",
       "905            4  this is a great product  i used it one time an...   \n",
       "906            4  amazing duo  i drink tea and have not been abl...   \n",
       "907            4  a nice maintenance whitening product for regul...   \n",
       "908            5  will definitely buy again  i absolutely love t...   \n",
       "909            5  fast  easy  results   i had the please of tryi...   \n",
       "910            4  good product  i received the crest 3d white br...   \n",
       "911            3  fresh breath feel  i was very excited to recei...   \n",
       "912            5  crest is the best  i am trying this product fo...   \n",
       "913            5  this new product is completely different and h...   \n",
       "\n",
       "     sentiment_score                                          key_words  \n",
       "0             0.9185  teeth, product, step, gel, crest, whitestrips,...  \n",
       "1             0.9359  step, day, teeth, system, use, mission, coffee...  \n",
       "2             0.9896  teeth, system, brilliance, cleansing, dentist,...  \n",
       "3             0.8689      product, teeth, whitening, tube, tubes, mouth  \n",
       "4             0.9891  home, whitening, brilliance, cleansing, thanks...  \n",
       "5            -0.6385  teeth, product, people, mouth, parts, crest, w...  \n",
       "6             0.9659  system, teeth, diffrent, time, way, mouthwashe...  \n",
       "7             0.9359          product, whitening, kit, dentist, results  \n",
       "8             0.9851  product, friends, mission, word, smile, review...  \n",
       "9             0.0303  product, step, whitening, week, time, products...  \n",
       "10            0.9152  product, bed, right, mouth, process, feeling, ...  \n",
       "11            0.9702  system, crest, one, teeth, cleansing, coffee, ...  \n",
       "12            0.9303  product, teeth, amazon, everyone, people, expe...  \n",
       "13            0.8944  step, product, cap, days, teeth, toothpaste, p...  \n",
       "14            0.9246  teeth, pregnancy, product, answer, time, tooth...  \n",
       "15            0.8057                                     teeth, product  \n",
       "16            0.8221  areas, results, sensitivity, teeth, product, i...  \n",
       "17            0.9596  breath, products, teeth, mouth, time, whiter, ...  \n",
       "18            0.9552     sample, love, crest, smile, thanks, toothpaste  \n",
       "19            0.6980  toothpaste, spots, gums, feeling, label, produ...  \n",
       "20            0.9841  product, whiter, paste, teeth, chance, mail, s...  \n",
       "21            0.9727  teeth, toothpaste, day, steps, strips, work, s...  \n",
       "22            0.9695       difference, it-, stuff, part, minutes, mouth  \n",
       "23            0.9863  product, taste, gums, tubes, minutes, day, pac...  \n",
       "24            0.9670  difference, brilliance, teeth, products, issue...  \n",
       "25            0.9530  difference, trial, anyone, money, way, product...  \n",
       "26            0.8979                           teeth, expierence, stuff  \n",
       "27           -0.2803   teeth, use, fan, weeks, bzzagent, product, crest  \n",
       "28            0.8360      teeth, picture, paste, crest, coffee, drinker  \n",
       "29            0.9118  way, system, teeth, guinea, color, bzzagent, s...  \n",
       "..               ...                                                ...  \n",
       "884           0.9500  non, crest, whitening, teeth, future, sensitiv...  \n",
       "885           0.9915  whitening, teeth, steps, lot, difference, coff...  \n",
       "886           0.9826  crest, teeth, brilliance, product, minute, ste...  \n",
       "887           0.9697  teeth, trays, whiter, couple, cream, crest, mi...  \n",
       "888           0.9927  one, day, teeth, today, pictures, difference, ...  \n",
       "889           0.9511  whitening, teeth, time, difference, toothpaste...  \n",
       "890           0.9694  teeth, toothpaste, step, crest, product, side,...  \n",
       "891           0.9741  product, teeth, step, smile, cleanser, flavor,...  \n",
       "892           0.9631  system, step, toothpaste, results, tube, denti...  \n",
       "893           0.9321  teeth, whiter, week, difference, whitens, test...  \n",
       "894           0.3837          love, toothpaste, week, set, kit, results  \n",
       "895           0.9970  system, brilliance, kit, step, crest, use, mou...  \n",
       "896           0.9795  product, teeth, toothpaste, step, mouth, textu...  \n",
       "897           0.7910  teeth, step, product, day, mouth, plenty, peop...  \n",
       "898           0.9926  teeth, product, toothpaste, stains, wine, ques...  \n",
       "899           0.9844  step, teeth, product, fluoride, gel, damage, t...  \n",
       "900           0.9758  teeth, products, product, difference, cleansin...  \n",
       "901           0.9890  teeth, texture, sample, week, smile, gunk, cre...  \n",
       "902           0.9274  thanks, lineup, whitening, health, appearance,...  \n",
       "903           0.9760  system, results, product, crest, toothpaste, s...  \n",
       "904           0.9744  product, toothpaste, opinion, agents, cap, foa...  \n",
       "905           0.9686  product, time, minute, staining, teeth, taste,...  \n",
       "906           0.9313  teeth, duo, bzzzagent, dentist, time, shade, t...  \n",
       "907           0.9667  product, teeth, peroxide, whitening, crest, te...  \n",
       "908           0.9359  week, part, bzzagent, product, crest, teeth, o...  \n",
       "909           0.9743  results, whitening, teeth, product, strips, mi...  \n",
       "910           0.9735  teeth, product, system, difference, minute, cl...  \n",
       "911           0.8496  breath, week, difference, tube, freebie, bzzag...  \n",
       "912           0.9393  teeth, product, difference, hundreds, counter,...  \n",
       "913           0.9459  product, taste, crest, minty, past, difference...  \n",
       "\n",
       "[914 rows x 6 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prod_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(prod_A['key_words'], prod_A['sentiment_score'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer()\n",
    "training_features = tf_vectorizer.fit_transform(X_train)\n",
    "test_features = tf_vectorizer.transform(X_test)\n",
    "\n",
    "L = tf_vectorizer.get_feature_names() \n",
    "\n",
    "Dict_features = {idx: value for idx, value in enumerate(L)}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.73105836e-01,  8.67692450e-02, -2.67565179e+00, -1.01156233e+00,\n",
       "       -5.24347454e-01, -1.95636754e+00,  1.71816638e+00, -1.30800537e+00,\n",
       "        3.96952693e-01,  4.29011529e-02,  8.69669185e-01,  2.58242110e+00,\n",
       "        1.86586599e+00,  1.66118320e+00, -7.99797585e-02,  9.85207657e-01,\n",
       "        8.57766967e-02,  1.81292634e+00,  6.95542944e-02, -7.80531437e-01,\n",
       "       -3.07918632e-01, -2.49524447e-01,  4.50096064e-01, -1.39557674e+00,\n",
       "       -4.06438600e-01,  3.28305372e-01, -6.09422191e-01,  1.32194915e+00,\n",
       "        2.86343378e-01, -2.55827630e+00,  1.13609406e+00, -9.06403203e-01,\n",
       "       -1.23594487e-01, -1.75100495e+00, -1.81602657e+00, -2.41444696e+00,\n",
       "       -3.76939526e-02,  7.94027439e-01, -2.74109041e-01,  8.84823120e-02,\n",
       "        8.37469506e-02, -6.42603179e-01, -3.76882581e-01,  1.24636113e+00,\n",
       "       -1.35771034e+00,  1.04661060e+00,  6.90929270e-01,  6.11466446e-01,\n",
       "        1.04676790e-01,  6.89892528e-01, -4.74573190e-01,  4.12993679e-01,\n",
       "       -6.26455092e-01, -3.00952478e-01, -2.87112393e-02,  9.76047449e-02,\n",
       "       -8.38455208e-01, -2.09507147e-01,  2.53011753e+00, -6.00355923e-01,\n",
       "        1.15667445e+00, -3.48509535e-01, -9.08814057e-01,  1.17004396e+00,\n",
       "       -9.40617730e-02,  8.36696655e-01, -9.32453477e-01,  2.99702022e+00,\n",
       "        7.81564135e-01, -3.76827096e-01, -1.04516368e+00, -1.75484818e+00,\n",
       "       -6.18489527e-01,  3.65237779e+00, -5.09932736e-01, -4.14519163e-01,\n",
       "       -2.15915471e-01, -1.11850626e-01,  2.64199778e-01,  2.19008266e+00,\n",
       "        4.23019972e-01, -4.55665429e-01,  1.33709855e+00, -4.80382457e-01,\n",
       "        1.05150660e-01,  5.26848497e-01, -8.98941174e-01,  8.36039143e-01,\n",
       "        2.43583154e-01, -4.33493289e-01, -5.77169349e-01, -6.91713404e-01,\n",
       "        1.69865343e+00,  2.12432503e-01, -2.09165627e-01, -4.93389780e-03,\n",
       "       -2.06699202e+00,  2.89458618e-01, -3.76939526e-02, -9.43531029e-02,\n",
       "        1.52497108e-01, -1.57908141e-03, -1.10157267e+00,  1.56577855e+00,\n",
       "       -1.88513122e-01, -2.68994999e-01,  1.90068717e+00,  2.80438099e-01,\n",
       "        1.58071762e-01,  2.70888203e-01, -2.62660512e-01,  3.27097971e-01,\n",
       "        1.27797643e-01,  1.08367105e-01, -3.64944872e-01, -5.55348182e-01,\n",
       "       -9.39399724e-02, -1.00846864e+00, -3.40079346e-01, -7.16035986e-02,\n",
       "       -2.68994999e-01,  2.12432503e-01, -2.72787463e-01, -1.45343656e+00,\n",
       "       -1.23594487e-01, -1.22635388e-01, -1.75183126e-01, -3.05154317e-01,\n",
       "        4.79909636e-01, -1.00846864e+00, -1.56114114e+00, -1.17829710e-01,\n",
       "        1.66857081e-01,  3.74371204e-01, -5.57402991e-01,  1.84733572e+00,\n",
       "        9.21974944e-01, -1.38595336e+00,  1.25667925e-01, -9.95461586e-01,\n",
       "       -2.05451375e+00, -1.06422597e+00,  8.78210266e-01, -1.80326157e-01,\n",
       "        1.00717871e+00,  1.42821954e+00, -1.06422597e+00, -5.24347454e-01,\n",
       "       -2.28430153e-01, -2.43865133e-01, -3.24164188e-01, -2.37521921e-01,\n",
       "        8.92877582e-01, -4.32732313e-01, -7.16035986e-02,  8.38330996e-01,\n",
       "       -2.46493337e+00, -3.91356761e-01,  6.95542944e-02,  5.16940854e-02,\n",
       "        1.46789035e-01, -3.80101219e-01, -2.16954544e+00,  1.51879272e+00,\n",
       "        4.63743240e-01, -6.24173404e-01,  2.06282764e-01, -3.71098168e+00,\n",
       "       -5.80671837e-02,  2.80438099e-01, -6.52281030e-01, -1.65744067e+00,\n",
       "        3.48640774e-01,  5.38454086e-01, -1.84879500e-01, -3.07870663e+00,\n",
       "        4.09034818e-03,  1.71438004e+00,  1.38963370e-01,  1.04676790e-01,\n",
       "       -7.42300635e-01, -5.40514837e-02, -1.06495332e+00, -3.16657820e-01,\n",
       "        3.53716233e-01,  1.32993575e+00,  1.19510345e+00, -1.09069655e+00,\n",
       "       -1.48760088e-01,  6.90929270e-01,  4.98069174e-01, -3.18966278e-01,\n",
       "       -1.78502359e+00,  1.51879272e+00, -3.14414247e-01, -1.43163994e-02,\n",
       "       -2.55584726e-01, -2.39315400e-01, -3.61211005e-01, -4.11706371e-01,\n",
       "       -1.62109433e+00,  7.30835641e-03,  2.60297369e+00,  7.64462480e-01,\n",
       "       -2.72335376e+00, -8.56089406e-01,  1.58141019e-01,  2.04729186e+00,\n",
       "        2.90021975e+00,  4.09034818e-03, -7.84378010e-01,  1.50518649e+00,\n",
       "        6.95041401e-01, -4.32732313e-01,  1.44775386e+00, -5.83034925e-01,\n",
       "       -6.48704040e-01, -7.33240597e-02,  4.02744629e-02, -1.80326157e-01,\n",
       "       -1.09100528e-01,  7.28031722e-02, -3.86724835e+00,  1.07471068e-01,\n",
       "        2.17711287e+00, -8.90220976e-02,  8.20101669e-02,  1.28715211e+00,\n",
       "       -1.40584338e+00, -2.22517586e-01, -1.78860854e-01, -1.49850959e+00,\n",
       "        8.94687356e-01, -3.48450178e-01, -4.33493289e-01, -1.82343249e-01,\n",
       "        1.94032034e-01,  6.33536857e-01, -1.95636754e+00,  1.28096329e+00,\n",
       "       -7.45102373e-01,  3.60568201e-01, -1.61536057e-01, -1.07795708e-01,\n",
       "        4.72769110e-01,  4.31807613e-01, -2.04431335e+00,  1.45310925e+00,\n",
       "        7.62665688e-01,  2.72881756e-01,  2.03036404e+00, -5.20182883e-01,\n",
       "       -5.28372042e-01,  2.17076505e-02, -5.17583509e-01, -1.77086123e+00,\n",
       "        1.17352895e+00,  4.84318383e-01,  3.76367041e-01, -2.69570715e-01,\n",
       "       -1.28038728e+00,  6.76038964e-02,  1.97133343e-01,  1.15457331e+00,\n",
       "       -1.98867820e+00,  1.41576559e-01, -1.37217121e+00,  2.14254859e+00,\n",
       "       -2.12871053e+00,  3.80817084e-01,  1.99137339e-01,  8.07122163e-01,\n",
       "        1.30157359e+00,  2.80438099e-01,  3.09862783e-02, -1.70249407e+00,\n",
       "       -1.78860854e-01, -6.58880116e-01,  8.20101669e-02,  1.08367105e-01,\n",
       "        1.24648481e+00, -1.34648485e+00,  2.49966054e-01,  1.41576559e-01,\n",
       "        4.28957579e-01,  3.00741749e-04, -3.09367001e+00,  4.02325916e-01,\n",
       "        8.19356561e-01,  1.01971304e+00,  1.65498653e+00, -8.67438739e-01,\n",
       "        8.02578156e-01,  1.18339492e+00, -3.57061897e-01, -4.47985574e-01,\n",
       "        8.19074506e-01, -1.14367445e-01, -7.36729677e-01, -3.05154317e-01,\n",
       "        2.74623901e-01, -1.67565400e-01,  5.56958711e-01, -2.99206434e+00,\n",
       "       -2.65451917e-01,  6.90929270e-01,  1.36895199e-01,  2.63172097e-01,\n",
       "        1.36016975e-01,  2.81218821e-01,  1.65157115e+00,  7.74985375e-02,\n",
       "       -4.80382457e-01, -2.07458138e-02,  2.72881756e-01, -2.10207816e-01,\n",
       "       -7.42141755e-01,  3.42537071e-01,  5.98920338e-01, -8.21214372e-01,\n",
       "       -2.97146310e-01, -4.93389780e-03, -2.74495704e-02, -4.60974847e-01,\n",
       "        2.51396273e+00,  6.41106782e-01,  6.53354469e-02,  7.94027439e-01,\n",
       "        2.80728686e-01,  2.03347392e+00,  5.11482216e-01,  1.83232863e+00,\n",
       "        1.19802048e-01,  2.74623901e-01,  5.99378633e-02, -3.71714280e-01,\n",
       "        4.79909636e-01,  7.69460900e-01, -9.36261825e-01,  3.80817084e-01,\n",
       "       -8.22271338e-01,  4.67298609e-01,  3.60568201e-01,  1.43530175e+00,\n",
       "       -7.99638547e-02, -1.09100528e-01, -8.87235353e-01, -7.03532350e-01,\n",
       "        2.06282764e-01,  1.05368590e+00,  7.09972241e-01, -2.09790581e+00,\n",
       "       -2.23751072e+00, -3.38875395e+00,  4.09034818e-03, -4.32123730e+00,\n",
       "       -7.31158985e-01,  8.71045891e-01,  7.02350902e-02,  1.29069246e-01,\n",
       "        7.29152336e-01, -1.07795708e-01,  5.47573412e-01, -4.96866742e-01,\n",
       "       -2.30934452e-01, -1.06230399e+00,  1.94311543e-01,  1.47978285e+00,\n",
       "        2.91005855e-01,  1.20892083e+00, -2.65326081e-01, -3.82890438e-01,\n",
       "       -9.20072121e-02,  5.70297255e-02,  2.84177604e-01, -5.79012544e-01,\n",
       "       -9.14166318e-01,  6.95542944e-02, -6.79175547e-01,  1.04690363e+00,\n",
       "       -1.64697523e-01,  7.96153102e-01,  3.91922290e-01, -5.55677275e-02,\n",
       "        7.69460900e-01, -2.10207816e-01, -5.88976817e-01,  2.21679231e+00,\n",
       "       -4.65070765e-01, -1.40584338e+00, -1.04516368e+00, -2.38360413e-01,\n",
       "        1.13995244e-01, -6.12180322e-01,  2.43941349e+00,  5.71065200e-01,\n",
       "       -3.19746812e+00,  3.20946451e-01,  3.96158383e+00, -2.57977563e-01,\n",
       "       -8.33279374e-01,  8.46691469e-01, -4.27326820e-01, -3.51180165e-01,\n",
       "        1.48837946e-01,  1.37973176e-01,  7.22559922e-01,  9.07803507e-01,\n",
       "       -4.31926878e-01,  1.07471068e-01,  1.13266392e+00, -2.53846412e-01,\n",
       "        1.12715479e-01, -6.32280335e-01,  6.27351389e-01, -8.38320521e-03,\n",
       "        6.65796783e-01,  2.50347721e-01, -3.18435077e-01,  1.35059387e+00,\n",
       "        8.63922235e-01,  7.10182742e-03, -8.43934094e-01,  2.66946137e-01,\n",
       "        4.72769110e-01, -3.19518734e-02, -8.30280388e-01, -4.95213488e-01,\n",
       "        1.72457618e-01,  4.05259378e-01,  4.08456474e+00,  7.94027439e-01,\n",
       "        1.74352825e-01, -2.70881436e-01,  1.78037944e+00, -2.91378304e-01,\n",
       "        1.60685519e+00, -3.30973164e-01,  5.69511577e-01, -3.89543475e-01,\n",
       "        1.47803965e+00,  6.75109028e-01, -7.05759520e-01,  1.65307138e-01,\n",
       "       -3.25332053e-01,  2.81218821e-01, -3.64152078e-01,  1.13995244e-01,\n",
       "       -7.99797585e-02, -1.02813888e-01, -8.06741282e-01,  7.39390872e-01,\n",
       "       -8.91765439e-01,  5.36824998e-01,  1.06908288e-01, -1.34901918e-02,\n",
       "       -8.78642276e-01, -1.70249407e+00,  2.12702209e-01,  1.47161798e-01,\n",
       "        4.98069174e-01, -4.17163874e-01,  1.05150660e-01, -2.26622202e-01,\n",
       "       -2.09507147e-01, -7.42141755e-01, -6.08538610e-01, -9.39399724e-02,\n",
       "        6.02473695e-01, -1.55510753e-01,  1.68578648e-01,  3.42537071e-01,\n",
       "        8.30550110e-01, -1.73994381e+00, -2.72787463e-01,  1.82009531e-01,\n",
       "       -1.01156233e+00,  5.90520702e-01,  2.18321606e-01,  3.42537071e-01,\n",
       "       -1.77935608e-02, -1.48760088e-01, -3.27997641e-01, -2.16325381e-01,\n",
       "       -9.54063897e-01,  8.74575447e-02, -9.54717526e-02,  7.67871478e-01,\n",
       "       -1.81522015e+00,  1.28577715e+00,  7.10045445e-01, -2.62058769e-01,\n",
       "       -2.56611593e+00, -9.41964981e-01,  1.01369885e+00, -7.84378010e-01,\n",
       "        2.49966054e-01,  1.74008173e+00,  4.91465766e-02, -1.85951659e-02,\n",
       "       -5.39657777e-02,  2.64199778e-01, -1.30199165e+00,  6.51406658e-02,\n",
       "        2.06115934e+00, -1.06230399e+00, -1.90503471e-01, -1.40584338e+00,\n",
       "        2.96933682e-01, -2.24972286e-01, -3.82291067e-02, -4.52596066e-01,\n",
       "       -1.16908613e-01, -2.52425488e-01, -1.58563547e+00,  1.41576559e-01,\n",
       "       -2.03542209e-01,  1.99137339e-01,  2.21389314e+00, -5.08117875e-01,\n",
       "       -1.77353951e+00,  7.28031722e-02, -3.05154317e-01, -7.35858187e-01,\n",
       "       -5.23981932e-01, -8.86669766e-01, -1.45351138e+00,  5.62682329e-01,\n",
       "        7.94027439e-01, -6.97021342e-01,  9.96223435e-01,  1.19811660e+00,\n",
       "        9.98635364e-01,  2.64199778e-01, -5.56006358e-01,  3.73842668e-01,\n",
       "        3.20946451e-01,  2.10690057e-01,  6.04539965e-01, -1.57908141e-03,\n",
       "       -3.87576035e-01, -2.09165627e-01,  2.71304812e-01, -1.11997988e+00,\n",
       "        4.88604316e-01,  1.45942429e+00,  8.01181874e-01, -1.06581817e+00,\n",
       "       -1.09241193e+00, -4.80289488e-01, -1.29291604e-03, -1.60252172e-01,\n",
       "       -8.24480553e-01, -3.24964957e-01,  1.19811660e+00,  6.44193785e-01,\n",
       "       -1.57908141e-03, -4.44414104e-01,  4.42054644e-01,  1.48899545e-01,\n",
       "        2.96933682e-01,  4.47978530e-01,  1.00535705e+00, -1.70418235e+00,\n",
       "       -5.88387667e-01,  1.79831404e+00,  6.76038964e-02,  1.08654840e+00,\n",
       "       -1.90424986e-01, -3.30960034e-01, -7.62431594e-01, -5.80671837e-02,\n",
       "       -3.78292310e-01,  1.04951235e+00, -2.11165400e+00,  6.96292691e-01,\n",
       "       -7.26381990e-01, -7.04197296e-01,  9.28339196e-01,  3.42386957e-01,\n",
       "        6.64469028e-02, -1.45351138e+00,  6.45634387e-01, -5.83034925e-01,\n",
       "        6.32753788e-01, -6.46569645e-01, -3.90614840e-01,  1.63803921e+00,\n",
       "       -2.08615454e-01, -1.27095456e+00,  3.46520590e-01,  2.68058267e-01,\n",
       "        1.75173865e-02, -1.29806970e+00,  8.06101760e-01, -2.47123639e-01,\n",
       "        5.90520702e-01,  2.49966054e-01, -2.46999684e-03, -5.28240444e-01,\n",
       "        5.05196889e-01,  1.43898493e+00,  1.73601243e-02,  1.31785449e+00,\n",
       "       -3.28853845e+00,  1.41576559e-01, -4.24427606e-01, -3.76939526e-02,\n",
       "        9.50848169e-02,  5.69511577e-01, -5.33766444e-01, -2.17738245e-01,\n",
       "       -5.53028381e-01,  6.10465305e-02, -1.32168914e+00,  1.09806309e+00,\n",
       "        6.45634387e-01, -3.26651296e-02,  2.58562908e-01, -1.46459906e+00,\n",
       "        7.51722404e-03, -9.06047529e-01, -6.55695839e-01,  3.42537071e-01,\n",
       "       -2.99917932e-01,  3.76695513e-01, -2.18367423e-01,  1.41576559e-01,\n",
       "       -5.80671837e-02,  1.68578648e-01, -6.48704040e-01, -4.49408664e-01,\n",
       "        3.93195673e-01, -9.62869832e-02,  5.17336507e-01, -2.82732040e-01,\n",
       "       -1.18205989e-01,  1.90854009e+00,  1.28577715e+00,  1.04216183e+00,\n",
       "       -8.65667097e-01, -5.83034925e-01, -8.37569290e-01,  8.20101669e-02,\n",
       "        2.90940335e-01,  2.80438099e-01,  2.10186675e+00,  4.09759094e-01,\n",
       "        5.98663808e-01, -1.66235966e-01, -3.96065894e-01,  1.20932061e-01,\n",
       "       -7.49663582e-01, -9.83067604e-01,  5.58121608e-01,  1.16848826e+00,\n",
       "       -5.67378334e-02,  1.85527909e-01, -3.13394566e-02,  8.72845803e-02,\n",
       "       -1.73435426e+00,  4.65441347e-01,  1.28221611e+00,  9.61471546e-01,\n",
       "        6.32284150e-02,  9.94475865e-01, -5.39657777e-02, -3.57061897e-01,\n",
       "        6.50321306e-01,  7.41452369e-01, -8.28500940e-01,  2.78457430e-01,\n",
       "        4.23833361e-01, -1.08000074e+00,  2.33335631e-02, -4.32732313e-01,\n",
       "       -1.58977751e+00,  1.08367105e-01,  9.76853169e-01, -1.40111369e-01,\n",
       "       -2.39315400e-01,  1.74659755e-01,  7.02350902e-02,  8.72453363e-01,\n",
       "        1.36016975e-01])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf_model = LinearRegression()\n",
    "tf_model.fit(training_features, y_train)\n",
    "y_pred = tf_model.predict(test_features)\n",
    "\n",
    "\n",
    "top_ten = np.argsort(tf_model.coef_)[675:685]\n",
    "\n",
    "top_ten_list = []\n",
    "for i in top_ten:\n",
    "    top_ten_list.append(Dict_features[i])\n",
    "    \n",
    "tf_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['future',\n",
       " 'minutes',\n",
       " 'spots',\n",
       " 'crest',\n",
       " 'paste',\n",
       " 'time',\n",
       " 'system',\n",
       " 'staining',\n",
       " 'brush',\n",
       " 'smile']"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RIDGE \n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "clf = Ridge(alpha=1.0)\n",
    "clf.fit(training_features, y_train) \n",
    "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
    "\n",
    "R_y_pred = clf.predict(test_features)\n",
    "\n",
    "\n",
    "top_ten = np.argsort(clf.coef_)[0:10]\n",
    "\n",
    "ttop_ten_list = []\n",
    "for i in top_ten:\n",
    "    top_ten_list.append(Dict_features[i])\n",
    "    \n",
    "top_ten_list \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Count Vectorizer \n",
    "##### TDIF counts less common words. Perhaps do count vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Transform each text into a vector of word counts\n",
    "C_vectorizer = CountVectorizer()\n",
    "cv_training_features = C_vectorizer.fit_transform(X_train)\n",
    "cv_test_features = C_vectorizer.transform(X_test)\n",
    "\n",
    "\n",
    "L2 = C_vectorizer.get_feature_names() \n",
    "\n",
    "Dict_features_2 = {idx: value for idx, value in enumerate(L2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aftertaste',\n",
       " 'favor',\n",
       " 'ffor',\n",
       " 'buzzagent',\n",
       " 'vanity',\n",
       " 'lineup',\n",
       " 'photos',\n",
       " 'coke',\n",
       " 'opiniom',\n",
       " 'bzzzagent']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "cv_model = LinearRegression()\n",
    "cv_model.fit(cv_training_features, y_train)\n",
    "y_pred = cv_model.predict(cv_test_features)\n",
    "\n",
    "\n",
    "top_ten2 = np.argsort(cv_model.coef_)[675:685]\n",
    "\n",
    "top_ten_list2 = []\n",
    "for i in top_ten2:\n",
    "    top_ten_list2.append(Dict_features_2[i])\n",
    "    \n",
    "top_ten_list2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agent',\n",
       " 'brush',\n",
       " 'testers',\n",
       " 'staining',\n",
       " 'smoking',\n",
       " 'freebie',\n",
       " 'bonus',\n",
       " 'spots',\n",
       " 'alternative',\n",
       " 'car']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## RIDGE \n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "clf2 = Ridge(alpha=1.0)\n",
    "clf2.fit(cv_training_features, y_train) \n",
    "Ridge(alpha=1, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "      normalize=False, random_state=None, solver='auto', tol=0.001)\n",
    "\n",
    "R_y_pred = clf2.predict(cv_test_features)\n",
    "\n",
    "\n",
    "top_ten = np.argsort(clf2.coef_)[675:685]\n",
    "\n",
    "top_ten_list_4 = []\n",
    "for i in top_ten:\n",
    "    top_ten_list_4.append(Dict_features_2[i])\n",
    "    \n",
    "top_ten_list_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if these features are negative or positive\n",
    "# Maybe split reviews in negative or positive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RF(product, vectorizer=CountVectorizer()):\n",
    "\n",
    "\n",
    "    ''' \n",
    "\n",
    "    Input product data frame\n",
    "    Returns train/test split \n",
    "    Vectorizes data, and creates dictionary of {index:feature_name}\n",
    "    Inputs vectorized data into a ridge regression to get coefficents of each features\n",
    "    Returns top negative values and top positive values\n",
    "\n",
    "    ''' \n",
    "\n",
    "    #Returns train/test split \n",
    "    \n",
    "    y = product['sentiment_score']\n",
    "\n",
    "\n",
    "    #Vectorizes data, and creates dictionary of {index:feature_name}\n",
    "\n",
    "    X = vectorizer.fit_transform(product['key_words'])\n",
    "    \n",
    "\n",
    "    L = vectorizer.get_feature_names() \n",
    "    Dict_features = {idx: value for idx, value in enumerate(L)}\n",
    "\n",
    "\n",
    "    \n",
    "    regr = RandomForestRegressor(max_depth=3, random_state=0, n_estimators=100)\n",
    "    regr.fit(X, y)\n",
    "    RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
    "               max_features='auto', max_leaf_nodes=None,\n",
    "               min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "               min_samples_leaf=1, min_samples_split=2,\n",
    "               min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
    "               oob_score=False, random_state=0, verbose=0, warm_start=False)\n",
    "    \n",
    "\n",
    "    #Gets top ten features based on largest coefficents!!! (Here should return largest/ smallest for negative & positive)\n",
    "    top_ten = np.argsort(regr.feature_importances_)\n",
    "    top_ten_list = []\n",
    "    for i in top_ten:\n",
    "        top_ten_list.append(Dict_features[i])\n",
    "    \n",
    "    return top_ten_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_dict(prod_a, prod_b, lst):\n",
    "    sent_dict_a = {}\n",
    "    sent_dict_b = {}\n",
    "    for word in lst:\n",
    "        sent_dict_a[word] = [prod_a[prod_a['key_words'].str.contains(word)]['sentiment_score'].mean(),\n",
    "                      prod_a[prod_a['key_words'].str.contains(word)]['key_words'].count()] \n",
    "        \n",
    "        sent_dict_b[word] = [prod_b[prod_b['key_words'].str.contains(word)]['sentiment_score'].mean(),\n",
    "                      prod_b[prod_b['key_words'].str.contains(word)]['key_words'].count()] \n",
    "        \n",
    "    df_a = pd.DataFrame.from_dict(sent_dict_a, orient='index', \n",
    "                                  columns=['Product_A_avg_sentiment_score', 'Product_A_review_count'])\n",
    "    \n",
    "    df_b = pd.DataFrame.from_dict(sent_dict_b, orient='index',\n",
    "                                  columns=['Product_B_avg_sentiment_score', 'Product_B_review_count'])\n",
    "    \n",
    "    \n",
    "    result = pd.concat([df_a, df_b], axis=1)\n",
    "                       \n",
    " \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_A_avg_sentiment_score</th>\n",
       "      <th>Product_A_review_count</th>\n",
       "      <th>Product_B_avg_sentiment_score</th>\n",
       "      <th>Product_B_review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alternative</th>\n",
       "      <td>0.945600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>courtesy</th>\n",
       "      <td>0.917600</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>staining</th>\n",
       "      <td>0.900493</td>\n",
       "      <td>15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timing</th>\n",
       "      <td>0.954200</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freebie</th>\n",
       "      <td>0.849600</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>whiteners</th>\n",
       "      <td>0.963529</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>places</th>\n",
       "      <td>0.778400</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diamond</th>\n",
       "      <td>0.900033</td>\n",
       "      <td>3</td>\n",
       "      <td>0.9950</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>commitment</th>\n",
       "      <td>0.826700</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dollars</th>\n",
       "      <td>0.989600</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Product_A_avg_sentiment_score  Product_A_review_count  \\\n",
       "alternative                       0.945600                       1   \n",
       "courtesy                          0.917600                       9   \n",
       "staining                          0.900493                      15   \n",
       "timing                            0.954200                       2   \n",
       "freebie                           0.849600                       1   \n",
       "whiteners                         0.963529                       7   \n",
       "places                            0.778400                       1   \n",
       "diamond                           0.900033                       3   \n",
       "commitment                        0.826700                       1   \n",
       "dollars                           0.989600                       1   \n",
       "\n",
       "             Product_B_avg_sentiment_score  Product_B_review_count  \n",
       "alternative                         0.9413                       1  \n",
       "courtesy                               NaN                       0  \n",
       "staining                               NaN                       0  \n",
       "timing                                 NaN                       0  \n",
       "freebie                                NaN                       0  \n",
       "whiteners                              NaN                       0  \n",
       "places                                 NaN                       0  \n",
       "diamond                             0.9950                       1  \n",
       "commitment                             NaN                       0  \n",
       "dollars                             0.9576                       1  "
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_dict(prod_A, prod_B, Vec_Ridge(prodab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "\n",
    "def Vec_Ridge(product, vectorizer=CountVectorizer()):\n",
    "\n",
    "\n",
    "    ''' \n",
    "\n",
    "    Input product data frame\n",
    "    Returns train/test split \n",
    "    Vectorizes data, and creates dictionary of {index:feature_name}\n",
    "    Inputs vectorized data into a ridge regression to get coefficents of each features\n",
    "    Returns top negative values and top positive values\n",
    "\n",
    "    ''' \n",
    "\n",
    "    #Returns train/test split \n",
    "    X_train, X_test, y_train, y_test = train_test_split(product['key_words'], product['sentiment_score'], test_size=0.33, random_state=42)\n",
    "\n",
    "\n",
    "    #Vectorizes data, and creates dictionary of {index:feature_name}\n",
    "\n",
    "    training_features = vectorizer.fit_transform(X_train)\n",
    "    test_features = vectorizer.transform(X_test)\n",
    "\n",
    "    L = vectorizer.get_feature_names() \n",
    "    Dict_features = {idx: value for idx, value in enumerate(L)}\n",
    "\n",
    "\n",
    "    #Inputs vectorized data into a ridge regression to get coefficents of each features\n",
    "    clf = Ridge(alpha=1.0)\n",
    "    clf.fit(training_features, y_train) \n",
    "    Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
    "        normalize=False, random_state=None, solver='auto', tol=0.001)\n",
    "\n",
    "    y_pred = clf.predict(test_features)\n",
    "\n",
    "    #Gets top ten features based on largest coefficents!!! (Here should return largest/ smallest for negative & positive)\n",
    "    top_ten = np.argsort(clf.coef_)[:-10 - 1:-1]\n",
    "    top_ten_list = []\n",
    "    for i in top_ten:\n",
    "        top_ten_list.append(Dict_features[i])\n",
    "    \n",
    "    return top_ten_list\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alternative',\n",
       " 'courtesy',\n",
       " 'staining',\n",
       " 'timing',\n",
       " 'freebie',\n",
       " 'whiteners',\n",
       " 'places',\n",
       " 'diamond',\n",
       " 'commitment',\n",
       " 'dollars']"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vec_Ridge(prodab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
